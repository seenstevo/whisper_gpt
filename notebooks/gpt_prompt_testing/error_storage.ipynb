{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Aim is to get errors into correct format\n",
    "2) Second aim is to understand how to GPT can use the error file/DB to generate content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_counter(messages):\n",
    "    '''\n",
    "    Function to use encoding of a message and return the number of tokens used\n",
    "    '''\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0301\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4\n",
    "        num_tokens += len(encoding.encode(message['content']))\n",
    "    return num_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_checker = '''\\\n",
    "Eres un experto en español que deberá \"Corregir e Identificar\" errores en un texto de un no nativo. \\\n",
    "Para corregir los errores, primero generarás una versión corregida del texto. Considerarás el contexto del texto al hacer esta versión corregida. \\\n",
    "Después del texto corregido, utilizarás esta versión corregida para crear una tabla. La tabla tendrá tres columnas: Errores, Correcciónes, Etiquetas. \\\n",
    "Asegúrate de que la \"Corrección\" mantenga el mismo significado que el \"Error\". \\\n",
    "Clasifica el tipo de error y despues utiliza la etiqueta más apropiada de esta lista separada por comas: \\\n",
    "['ser/estar', 'tiempo_verbal', 'subjuntivo', 'preposición', 'concordancia_de_género', 'adverbio', 'artículo', 'orden_de_palabras', \\\n",
    "'elección_de_palabras', 'lo/el/la_que', 'pronombre_directo/indirecto', pretérito_imperfecto_del_subjuntivo, 'otro']\\\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt_checker = '''\n",
    "# You are a Spanish expert who will need to \"Correct and Identify\" errors in a text from a non-native. \n",
    "# In order to correct the errors, you will first generate a corrected version of the text with the section header \"Corrected Text\" followed by a newline. \n",
    "# You will consider the context of the text in making this corrected version. \n",
    "# After the corrected text, you will use this corrected version to make a table. The table will have three columns: Error, Correction, Tag. \n",
    "# Make sure that the Correction maintains the same meaning as the Error. \n",
    "# Use the most appropriate Tag from this comma separated list: ['past_tense', 'subjunctive', 'preposition', 'gender_agreement', 'adverb', 'article', \n",
    "# 'word_order', 'word_choice', 'lo/el/la_que', 'direct/indirect_pronoun', 'other']. \n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_check(context, transcription):\n",
    "    '''\n",
    "    Here we pass previous user and assistant interactions (context) plus the latest text (transcription) wrapped in an instruction to identify errors.\n",
    "    '''\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt_checker}]\n",
    "    messages.append(context[0])\n",
    "    messages.append(context[1])\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Corrige e identifica los errores del siguiente texto: ```{transcription}```. \\\n",
    "        Responde en formato JSON con las claves: 'Correction' y 'Table'\"})\n",
    "\n",
    "    response = openai.ChatCompletion.create(model = \"gpt-3.5-turbo\", messages = messages, temperature = 0, max_tokens = 1000)\n",
    "    return response[\"choices\"][0][\"message\"]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [{'role': 'user', 'content': 'Hola, encantado a conocerte.'},\n",
    "           {'role': 'assistant', 'content': '¿Qúe has hecho este fin de semana?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = \"He ido al parque por ver cosas y hacía muchas cosas. Había una fiesta y la dije a mi amiga que vamos. Lo que me gusta mucho está la fiesta. Si era rico, habría hecho más.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = error_check(context, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Correction\": \"Fui al parque para ver cosas e hice muchas cosas. Había una fiesta y le dije a mi amiga que fuéramos. Me gusta mucho la fiesta. Si fuera rico, habría hecho más.\",\n",
      "    \"Table\": [\n",
      "        {\n",
      "            \"Errores\": \"por ver\",\n",
      "            \"Correcciones\": \"para ver\",\n",
      "            \"Etiquetas\": \"preposición\"\n",
      "        },\n",
      "        {\n",
      "            \"Errores\": \"hacía\",\n",
      "            \"Correcciones\": \"hice\",\n",
      "            \"Etiquetas\": \"tiempo_verbal\"\n",
      "        },\n",
      "        {\n",
      "            \"Errores\": \"la dije\",\n",
      "            \"Correcciones\": \"le dije\",\n",
      "            \"Etiquetas\": \"pronombre_directo/indirecto\"\n",
      "        },\n",
      "        {\n",
      "            \"Errores\": \"que vamos\",\n",
      "            \"Correcciones\": \"que fuéramos\",\n",
      "            \"Etiquetas\": \"tiempo_verbal\"\n",
      "        },\n",
      "        {\n",
      "            \"Errores\": \"está\",\n",
      "            \"Correcciones\": \"está la\",\n",
      "            \"Etiquetas\": \"artículo\"\n",
      "        },\n",
      "        {\n",
      "            \"Errores\": \"Si era\",\n",
      "            \"Correcciones\": \"Si fuera\",\n",
      "            \"Etiquetas\": \"subjuntivo\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_table = pd.DataFrame({'Student': [transcription], 'Teacher': [response_dict['Correction']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_table = pd.DataFrame(response_dict['Table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['por ver', 'para ver', 'preposición'],\n",
       " ['hacía', 'hice', 'tiempo_verbal'],\n",
       " ['la dije', 'le dije', 'pronombre_directo/indirecto'],\n",
       " ['que vamos', 'que fuéramos', 'tiempo_verbal'],\n",
       " ['está', 'está la', 'artículo'],\n",
       " ['Si era', 'Si fuera', 'subjuntivo']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_table.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_tables(error_check_response, transcription):\n",
    "    '''\n",
    "    We pass the error_check response to log two types of data in two tables.\n",
    "    The first is the pair of student text and the teacher correction/improvement.\n",
    "    The second are the rows of Error, Correction and Tag. \n",
    "    '''\n",
    "    error_dict = json.loads(error_check_response)\n",
    "    \n",
    "    student_teacher_row = pd.DataFrame({'Student': [transcription], 'Teacher': [error_dict['Correction']]}).values.tolist()\n",
    "    add_rows('/home/sean/Documentos/AI_projects/whisper_gpt/tables/student_teacher.csv', student_teacher_row)\n",
    "    \n",
    "    error_rows = pd.DataFrame(error_dict['Table']).values.tolist()\n",
    "    add_rows('/home/sean/Documentos/AI_projects/whisper_gpt/tables/errors.csv', error_rows)\n",
    "    \n",
    "    \n",
    "    \n",
    "def add_rows(old_table: str, new_rows: list):\n",
    "    \n",
    "    with open(old_table, 'a', newline = '') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(new_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tables(response, transcription)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_checker = '''\\\n",
    "Eres un profesor de español divertido a quien le gusta enseñar mediante la demostración de español correcto. \\\n",
    "Producirás un texto de no más de 100 palabras que sea interesante y relevante para tu estudiante, utilizando el contexto de un \"Tema\" dado. \\\n",
    "El texto será natural y conversacional en estilo e incorporará el uso del algunos \"Correcciónes\" dados en forma de tabla. \\\n",
    "No muestres los \"Errores\" de esta tabla en el texto.\\\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt_checker = '''\\\n",
    "# You are a fun Spanish teacher who likes to teach by demonstration of correct Spanish. \\\n",
    "# You will produce a text of no more than 100 words that is interesting and relevant to your student by using the context of a given \"Theme\". \\\n",
    "# The text is naturalistic and conversational in style and will incorporate the \"Correccion\" use of some given \"Errors\". \\\n",
    "# Do not show the incorrect versions. \\\n",
    "# After the text, you will produce a test of 3 questions that get the student to use the corrected versions of the \"Errors\".\\\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_errors(errors, theme):\n",
    "    '''\n",
    "    This function seeks to create a small example based on a theme that highlights the correct way to use a word/phrase\n",
    "    '''\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt_checker}]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Usando la tabla abajo, genera un texto divertido e interasante basado en el sigiente tema: ```{theme}```\\\n",
    "        \\n```Tabla:\\n{errors}```\"})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(model = \"gpt-3.5-turbo\", messages = messages, temperature = 0.8, max_tokens = 1000)\n",
    "    return response[\"choices\"][0][\"message\"]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = \"cricket\"\n",
    "errors = error_table.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Errores Correcciones             Etiquetas\n",
      "4     está      está la  elección_de_palabras\n",
      "0  por ver     para ver           preposición\n",
      "5   Si era     Si fuera            subjuntivo\n"
     ]
    }
   ],
   "source": [
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = use_errors(errors, theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola amigo! ¿Has jugado alguna vez al cricket? Es un deporte fascinante y muy popular en los países de habla inglesa. En mi opinión, el cricket está la altura del fútbol o el baloncesto. Siendo honesto, no sé mucho sobre el cricket, pero estoy emocionado para aprender más. Estoy por ver algunos juegos en vivo y en directo. Si fuera posible, me gustaría ver un partido en Australia, en el famoso Estadio Sydney Cricket Ground. ¿Te unirías a mí? Sería divertido aprender y experimentar algo nuevo juntos.\n"
     ]
    }
   ],
   "source": [
    "print(example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a quiz based on errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_checker = '''\\\n",
    "Eres un profesor de español que realiza exámenes orales para que tu estudiante practique la corrección de errores. \\\n",
    "Se te proporcionará una tabla con algunos errores y sus correcciones. \\\n",
    "Crearás dos tipos de preguntas. La primera involucre completar la palabra faltante. \n",
    "Por ejemplo: \"completa la siguiente oración: `Juan ___ en la universidad.`\" \\\n",
    "La segunda requerir la traducción de una frase a un sujeto, tiempo o contexto diferente. \\\n",
    "Por ejemplo: \"Cómo se dice `Me gusta ir al cine` pero en el pasado.\"\\\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_errors_quiz(errors):\n",
    "    '''\n",
    "    This function seeks to create a small example based on a theme that highlights the correct way to use a word/phrase\n",
    "    '''\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt_checker}]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Usando la tabla abajo, genera un exámen\\n```Tabla:\\n{errors}```\"})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(model = \"gpt-3.5-turbo\", messages = messages, temperature = 0.8, max_tokens = 1000)\n",
    "    return response[\"choices\"][0][\"message\"]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = use_errors_quiz(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examen Oral de Español\n",
      "\n",
      "Parte 1: Completar la palabra faltante\n",
      "\n",
      "1. ¿Dónde ___ tu hermana ahora mismo? (elección_de_palabras)\n",
      "2. Prefiero ir en coche ___ caminar. (preposición)\n",
      "3. Juan actúa como si ___ el dueño del mundo. (subjuntivo)\n",
      "4. ¿___ seguro de que quieres hacer eso? (elección_de_palabras)\n",
      "5. No puedo creer que ___ tan tarde. (subjuntivo)\n",
      "\n",
      "Parte 2: Traducción de frase\n",
      "\n",
      "1. ¿Cómo se dice \"Iré al parque mañana\" en pasado? (tiempo)\n",
      "2. ¿Cómo se dice \"Me gustaría tener un café\" en una forma más formal? (etiqueta)\n",
      "3. ¿Cómo se dice \"Ella estudia biología\" si el sujeto cambia a \"nosotros\"? (sujeto)\n",
      "4. ¿Cómo se dice \"No quiero ir al cine\" en una forma más amable? (etiqueta)\n",
      "5. ¿Cómo se dice \"Ellos están cansados\" si el tiempo cambia a futuro? (tiempo)\n"
     ]
    }
   ],
   "source": [
    "print(quiz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptspeak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
